{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pydicom as dicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series UID</th>\n",
       "      <th>Collection</th>\n",
       "      <th>3rd Party Analysis</th>\n",
       "      <th>Data Description URI</th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Study UID</th>\n",
       "      <th>Study Description</th>\n",
       "      <th>Study Date</th>\n",
       "      <th>Series Description</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Modality</th>\n",
       "      <th>SOP Class Name</th>\n",
       "      <th>SOP Class UID</th>\n",
       "      <th>Number of Images</th>\n",
       "      <th>File Size</th>\n",
       "      <th>File Location</th>\n",
       "      <th>Download Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>2.25.179810891732019793459496497832233425115.1</td>\n",
       "      <td>PDMR-Texture-Analysis</td>\n",
       "      <td>NO</td>\n",
       "      <td>https://doi.org/10.7937/3KQ0YK19</td>\n",
       "      <td>BL0382-F1232-1724</td>\n",
       "      <td>2.25.96089192699936339821029186870284643178</td>\n",
       "      <td>NCI PDMR Tumor Characterization</td>\n",
       "      <td>06-11-2020</td>\n",
       "      <td>TSE45 split</td>\n",
       "      <td>Philips Medical Systems</td>\n",
       "      <td>MR</td>\n",
       "      <td>Raw Data Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.66</td>\n",
       "      <td>1</td>\n",
       "      <td>265.47 KB</td>\n",
       "      <td>.\\PDMR-Texture-Analysis\\BL0382-F1232-1724\\06-1...</td>\n",
       "      <td>2023-11-17T16:10:23.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1.3.6.1.4.1.5962.1.2.0.1670154536.70508.0.175.2</td>\n",
       "      <td>PDMR-Texture-Analysis</td>\n",
       "      <td>NO</td>\n",
       "      <td>https://doi.org/10.7937/3KQ0YK19</td>\n",
       "      <td>BL0382-F1232-1728</td>\n",
       "      <td>1.3.6.1.4.1.5962.1.2.0.1670154536.70508.0.175.1</td>\n",
       "      <td>NCI PDMR Tumor Characterization</td>\n",
       "      <td>05-20-2020</td>\n",
       "      <td>PDM Mouse Overview</td>\n",
       "      <td>PixelMed</td>\n",
       "      <td>SR</td>\n",
       "      <td>Acquisition Context SR Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.88.71</td>\n",
       "      <td>1</td>\n",
       "      <td>4.41 KB</td>\n",
       "      <td>.\\PDMR-Texture-Analysis\\BL0382-F1232-1728\\05-2...</td>\n",
       "      <td>2023-11-17T16:10:24.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2.25.308200546840067706797055294221268540073.1</td>\n",
       "      <td>PDMR-Texture-Analysis</td>\n",
       "      <td>NO</td>\n",
       "      <td>https://doi.org/10.7937/3KQ0YK19</td>\n",
       "      <td>BL0382-F1232-1728</td>\n",
       "      <td>2.25.295695138875747345906456588608783888488</td>\n",
       "      <td>NCI PDMR Tumor Characterization</td>\n",
       "      <td>06-11-2020</td>\n",
       "      <td>TSE45 split</td>\n",
       "      <td>Philips Medical Systems</td>\n",
       "      <td>MR</td>\n",
       "      <td>Raw Data Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.66</td>\n",
       "      <td>1</td>\n",
       "      <td>265.46 KB</td>\n",
       "      <td>.\\PDMR-Texture-Analysis\\BL0382-F1232-1728\\06-1...</td>\n",
       "      <td>2023-11-17T16:10:27.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>2.25.308200546840067706797055294221268540073</td>\n",
       "      <td>PDMR-Texture-Analysis</td>\n",
       "      <td>NO</td>\n",
       "      <td>https://doi.org/10.7937/3KQ0YK19</td>\n",
       "      <td>BL0382-F1232-1728</td>\n",
       "      <td>2.25.295695138875747345906456588608783888488</td>\n",
       "      <td>NCI PDMR Tumor Characterization</td>\n",
       "      <td>06-11-2020</td>\n",
       "      <td>TSE45 split</td>\n",
       "      <td>Philips Medical Systems</td>\n",
       "      <td>MR</td>\n",
       "      <td>MR Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.4</td>\n",
       "      <td>36</td>\n",
       "      <td>22.51 MB</td>\n",
       "      <td>.\\PDMR-Texture-Analysis\\BL0382-F1232-1728\\06-1...</td>\n",
       "      <td>2023-11-17T16:10:45.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>2.25.243475922033648146678409629073405401370</td>\n",
       "      <td>PDMR-Texture-Analysis</td>\n",
       "      <td>NO</td>\n",
       "      <td>https://doi.org/10.7937/3KQ0YK19</td>\n",
       "      <td>997537-175-T-1327</td>\n",
       "      <td>2.25.244508863228859243918875004939444840754</td>\n",
       "      <td>NCI PDMR Tumor Characterization</td>\n",
       "      <td>11-14-2018</td>\n",
       "      <td>TSE45 split</td>\n",
       "      <td>Philips Medical Systems</td>\n",
       "      <td>MR</td>\n",
       "      <td>MR Image Storage</td>\n",
       "      <td>1.2.840.10008.5.1.4.1.1.4</td>\n",
       "      <td>36</td>\n",
       "      <td>22.51 MB</td>\n",
       "      <td>.\\PDMR-Texture-Analysis\\997537-175-T-1327\\11-1...</td>\n",
       "      <td>2023-11-17T16:12:46.909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Series UID             Collection  \\\n",
       "1198   2.25.179810891732019793459496497832233425115.1  PDMR-Texture-Analysis   \n",
       "1199  1.3.6.1.4.1.5962.1.2.0.1670154536.70508.0.175.2  PDMR-Texture-Analysis   \n",
       "1200   2.25.308200546840067706797055294221268540073.1  PDMR-Texture-Analysis   \n",
       "1201     2.25.308200546840067706797055294221268540073  PDMR-Texture-Analysis   \n",
       "1202     2.25.243475922033648146678409629073405401370  PDMR-Texture-Analysis   \n",
       "\n",
       "     3rd Party Analysis              Data Description URI         Subject ID  \\\n",
       "1198                 NO  https://doi.org/10.7937/3KQ0YK19  BL0382-F1232-1724   \n",
       "1199                 NO  https://doi.org/10.7937/3KQ0YK19  BL0382-F1232-1728   \n",
       "1200                 NO  https://doi.org/10.7937/3KQ0YK19  BL0382-F1232-1728   \n",
       "1201                 NO  https://doi.org/10.7937/3KQ0YK19  BL0382-F1232-1728   \n",
       "1202                 NO  https://doi.org/10.7937/3KQ0YK19  997537-175-T-1327   \n",
       "\n",
       "                                            Study UID  \\\n",
       "1198      2.25.96089192699936339821029186870284643178   \n",
       "1199  1.3.6.1.4.1.5962.1.2.0.1670154536.70508.0.175.1   \n",
       "1200     2.25.295695138875747345906456588608783888488   \n",
       "1201     2.25.295695138875747345906456588608783888488   \n",
       "1202     2.25.244508863228859243918875004939444840754   \n",
       "\n",
       "                    Study Description  Study Date  Series Description  \\\n",
       "1198  NCI PDMR Tumor Characterization  06-11-2020         TSE45 split   \n",
       "1199  NCI PDMR Tumor Characterization  05-20-2020  PDM Mouse Overview   \n",
       "1200  NCI PDMR Tumor Characterization  06-11-2020         TSE45 split   \n",
       "1201  NCI PDMR Tumor Characterization  06-11-2020         TSE45 split   \n",
       "1202  NCI PDMR Tumor Characterization  11-14-2018         TSE45 split   \n",
       "\n",
       "                 Manufacturer Modality                  SOP Class Name  \\\n",
       "1198  Philips Medical Systems       MR                Raw Data Storage   \n",
       "1199                 PixelMed       SR  Acquisition Context SR Storage   \n",
       "1200  Philips Medical Systems       MR                Raw Data Storage   \n",
       "1201  Philips Medical Systems       MR                MR Image Storage   \n",
       "1202  Philips Medical Systems       MR                MR Image Storage   \n",
       "\n",
       "                      SOP Class UID  Number of Images  File Size  \\\n",
       "1198     1.2.840.10008.5.1.4.1.1.66                 1  265.47 KB   \n",
       "1199  1.2.840.10008.5.1.4.1.1.88.71                 1    4.41 KB   \n",
       "1200     1.2.840.10008.5.1.4.1.1.66                 1  265.46 KB   \n",
       "1201      1.2.840.10008.5.1.4.1.1.4                36   22.51 MB   \n",
       "1202      1.2.840.10008.5.1.4.1.1.4                36   22.51 MB   \n",
       "\n",
       "                                          File Location  \\\n",
       "1198  .\\PDMR-Texture-Analysis\\BL0382-F1232-1724\\06-1...   \n",
       "1199  .\\PDMR-Texture-Analysis\\BL0382-F1232-1728\\05-2...   \n",
       "1200  .\\PDMR-Texture-Analysis\\BL0382-F1232-1728\\06-1...   \n",
       "1201  .\\PDMR-Texture-Analysis\\BL0382-F1232-1728\\06-1...   \n",
       "1202  .\\PDMR-Texture-Analysis\\997537-175-T-1327\\11-1...   \n",
       "\n",
       "           Download Timestamp  \n",
       "1198   2023-11-17T16:10:23.58  \n",
       "1199  2023-11-17T16:10:24.266  \n",
       "1200  2023-11-17T16:10:27.462  \n",
       "1201   2023-11-17T16:10:45.81  \n",
       "1202  2023-11-17T16:12:46.909  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = Path('manifest-1686081801328')  # Set your data folder here\n",
    "# Print metadata\n",
    "metadata_df = pd.read_csv(data_folder/'metadata.csv')\n",
    "metadata_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_paths = glob(str(data_folder/'PDMR-Texture-Analysis'/'*'))\n",
    "data_dict = {}\n",
    "for lvl1_path in level1_paths:\n",
    "    level2_paths = glob(f'{lvl1_path}/*')\n",
    "    lvl2_dict = {}\n",
    "    for lvl2_path in level2_paths:\n",
    "        lvl3_dict = {}\n",
    "        lvl3_paths = glob(f'{lvl2_path}/*')\n",
    "        for scan_path in lvl3_paths:\n",
    "            dcm_slices = glob(f'{scan_path}/*.dcm')\n",
    "            lvl3_dict[Path(scan_path).name] = dcm_slices\n",
    "        lvl2_dict[Path(lvl2_path).name] = lvl3_dict\n",
    "    data_dict[Path(lvl1_path).name] = lvl2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'segmentation_test\\\\3012 TSE45 split.nrrd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnrrd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data1, header1 \u001b[38;5;241m=\u001b[39m \u001b[43mnrrd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegmentation_test\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m3012 TSE45 split.nrrd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data2, header2 \u001b[38;5;241m=\u001b[39m nrrd\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation_test\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSegmentation.seg.nrrd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nrrd/reader.py:515\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, custom_field_map, index_order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, custom_field_map: Optional[NRRDFieldMap] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, index_order: IndexOrder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[npt\u001b[38;5;241m.\u001b[39mNDArray, NRRDHeader]:\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read a NRRD file and return the header and data\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    See :ref:`background/how-to-use:reading nrrd files` for more information on reading NRRD files.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m    :meth:`write`, :meth:`read_header`, :meth:`read_data`\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    516\u001b[0m         header \u001b[38;5;241m=\u001b[39m read_header(fh, custom_field_map)\n\u001b[1;32m    517\u001b[0m         data \u001b[38;5;241m=\u001b[39m read_data(header, fh, filename, index_order)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'segmentation_test\\\\3012 TSE45 split.nrrd'"
     ]
    }
   ],
   "source": [
    "import nrrd\n",
    "data1, header1 = nrrd.read('segmentation_test\\\\3012 TSE45 split.nrrd')\n",
    "data2, header2 = nrrd.read('segmentation_test\\\\Segmentation.seg.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 10\n",
    "\n",
    "def plot_scan(image_paths):\n",
    "    N = len(image_paths)\n",
    "    n_rows = int(np.ceil(N / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 14))\n",
    "    axes = axes.flatten()\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        ds = dicom.dcmread(img_path)\n",
    "        ds.pixel_array\n",
    "        axes[i].imshow(ds.pixel_array[200:-200])\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off') \n",
    "    return fig, axes\n",
    "\n",
    "def plot_single(image_paths, n=17):\n",
    "\n",
    "    ds = dicom.dcmread(image_paths[n])\n",
    "    img = ds.pixel_array[200:-200]\n",
    "    fig, ax = plt.subplots(figsize=(8, 12))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "lvl1_keys = list(data_dict.keys())\n",
    "for key1 in lvl1_keys:\n",
    "    lvl2_data = data_dict[key1]\n",
    "    lvl2_keys = list(lvl2_data.keys())\n",
    "    for key2 in lvl2_keys:\n",
    "        lvl3_data = data_dict[key1][key2]\n",
    "        lvl3_keys = list(lvl3_data.keys())\n",
    "        for scan_name in lvl3_keys: # Chosing second folder as it usually contains the correct scan with multiple images\n",
    "            scan_image_paths = data_dict[key1][key2][scan_name]\n",
    "            for path in scan_image_paths:\n",
    "                img_name = Path(path).stem\n",
    "                img_order = int(img_name.split('-')[1])\n",
    "                img_scan_name = scan_name\n",
    "                img_inspection_name = key2\n",
    "                img_inspection_date = ''.join(key2.split('-')[0:3])\n",
    "                img_specimen_name = key1\n",
    "                img_original_patient_id = ''.join(key2.split('-')[0:3])\n",
    "                img_mouse_id = key2.split('-')[-1]\n",
    "                \n",
    "\n",
    "            # #fig, axes = plot_scan(scan_image_paths)\n",
    "            # #fig.suptitle(key2) \n",
    "            # #fig.tight_layout()\n",
    "            # #fig.subplots_adjust(top=0.97)\n",
    "            # #fig.savefig(f'{key2}.png', transparent=True)\n",
    "            # fig_single, ax = plot_single(scan_image_paths)\n",
    "            # #fig_single.suptitle(key2)\n",
    "            # fig_single.tight_layout()\n",
    "            # fig_single.savefig(f'{key1}_{key2}_single.png', transparent=True)\n",
    "        #plt.subplots_adjust(wspace=0.1, hspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BL0382-F1232-1714', '144126-210-T-1669', '172845-121-T-1862', '698357-238-R-1953', '698357-238-R-1955', '146476-266-R-1621', '894883-131-R-2315', '833975-119-R-1572', '695669-166-R-2043', 'BL0382-F1232-1716', '521955-158-R4-2162', '625472-104-R-1544', '765638-272-R-2017', '146476-266-R-1630', '625472-104-R-1548', '765638-272-R-2007', '625472-104-R-1545', '698357-238-R-1977', 'BL0382-F1232-1728', '894883-131-R-2320', '779769-127-R-1675', '779769-127-R-1685', '146476-266-R-1623', '287954-098-R-1995', '833975-119-R-1584', '172845-121-T-1859', '172845-121-T-1847', '172845-142-T-1265', '172845-121-T-1853', '287954-098-R-2003', '287954-098-R-2004', '287954-098-R-1987', '146476-266-R-1631', '172845-142-T-1242', '144126-210-T-1664', '466636-57-R-444', '172845-142-T-1238', '698357-238-R-1970', '172845-142-T-1246', '521955-158-R4-2177', '146476-266-R-1616', '172845-142-T-1262', '695669-166-R-2051', '172845-142-T-1247', '833975-119-R-1568', '172845-142-T-1257', '172845-121-T-1854', '833975-119-R-1567', '997537-175-T-1330', '144126-210-T-1655', '625472-104-R-1536', '287954-098-R-1998', '521955-158-R4-2169', '833975-119-R-1576', '698357-238-R-1959', '146476-266-R-1615', '997537-175-T-1319', '287954-098-R-1994', 'LICENSE', '521955-158-R6-614', '833975-119-R-1570', '172845-121-T-1846', '894883-131-R-2321', '521955-158-R4-2171', '146476-266-R-1626', '521955-158-R4-2173', '695669-166-R-2037', '466636-57-R-463', '466636-57-R-446', '765638-272-R-2010', '146476-266-R-1628', '172845-142-T-1241', '779769-127-R-1678', '521955-158-R6-597', '165739-295-R-1188', '894883-131-R-2322', '521955-158-R6-516', '765638-272-R-2023', '172845-121-T-1855', '695669-166-R-2054', '765638-272-R-2008', '833975-119-R-1577', '466636-57-R-373', '172845-142-T-1260', '144126-210-T-1641', '765638-272-R-2011', '833975-119-R-1582', '172845-121-T-1858', '172845-121-T-1852', '172845-142-T-1259', '833975-119-R-1580', '172845-121-T-1860', '997537-175-T-1326', '144126-210-T-1658', '172845-121-T-1857', '698357-238-R-1980', '165739-295-R-1182', '625472-104-R-1541', '165739-295-R-1189', '146476-266-R-1625', '521955-158-R6-613', '165739-295-R-1179', '521955-158-R4-2175', '625472-104-R-1547', '146476-266-R-1632', '521955-158-R6-594', '146476-266-R-1629', '144126-210-T-1645', '779769-127-R-1691', '144126-210-T-1637', '165739-295-R-1191', '287954-098-R-1986', '146476-266-R-1627', '172845-121-T-1856', '625472-104-R-1542', '894883-131-R-2318', '997537-175-T-1321', '172845-121-T-1850', '144126-210-T-1668', '997537-175-T-1338', '521955-158-R4-2167', '172845-142-T-1254', '695669-166-R-2038', '997537-175-T-1331', 'BL0382-F1232-1724', 'BL0382-F1232-1711', '172845-121-T-1849', '172845-121-T-1848', '287954-098-R-1992', '165739-295-R-1195', '521955-158-R6-595', '625472-104-R-1550', '997537-175-T-1327', '146476-266-R-1622', '172845-121-T-1864', '521955-158-R4-2165', '165739-295-R-1181', '172845-121-T-1851', '172845-142-T-1244', '287954-098-R-1991', '466636-57-R-453', '165739-295-R-1192', '172845-121-T-1845', 'BL0382-F1232-1715', '146476-266-R-1624', '521955-158-R6-611', '172845-142-T-1243', '698357-238-R-1978', 'BL0382-F1232-1723', '695669-166-R-2048', 'BL0382-F1232-1718', '997537-175-T-1334', '765638-272-R-2012', '765638-272-R-2005', '695669-166-R-2044', '146476-266-R-1618', '833975-119-R-1583', '146476-266-R-1633', '695669-166-R-2039', '997537-175-T-1322', '521955-158-R4-2163', '172845-142-T-1261', '833975-119-R-1579', '172845-121-T-1861', '625472-104-R-1546', '165739-295-R-1185', '165739-295-R-1178', '287954-098-R-1999', '146476-266-R-1617', '833975-119-R-1575', '521955-158-R4-2179', '779769-127-R-1693', 'BL0382-F1232-1712', '172845-121-T-1863', '894883-131-R-2305', '172845-142-T-1250']\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/03-27-2020-638294773-NCI PDMR Tumor Characterization-99898/5013.000000-TSE45 split-163.1/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/04-10-2020-639495207-NCI PDMR Tumor Characterization-91016/4013.000000-TSE45 split-601.1/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/02-19-2020-MODELSR8-NCI PDMR Tumor Characterization-0.8.1/1.000000-PDM Mouse Overview-0.8.2/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/05-08-2020-641916342-NCI PDMR Tumor Characterization-34168/3012.000000-TSE45 split-356.1/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/04-24-2020-640712957-NCI PDMR Tumor Characterization-81043/3013.000000-TSE45 split-175.1/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/03-13-2020-637077206-NCI PDMR Tumor Characterization-06621/4013.000000-TSE45 split-309.1/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n",
      "['manifest-1686081801328/PDMR-Texture-Analysis/144126-210-T-1669/05-21-2020-643041872-NCI PDMR Tumor Characterization-25669/5012.000000-TSE45 split-363.1/1-1.dcm']\n",
      "Unable to convert the pixel data: one of Pixel Data, Float Pixel Data or Double Float Pixel Data must be present in the dataset\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "import os\n",
    "import nibabel as nib\n",
    "os.makedirs('images_2d', exist_ok=True)\n",
    "\n",
    "def convert_dicom_to_nifti(dicom_pixels):\n",
    "    # Stack the DICOM slices and convert to a NumPy array\n",
    "    # Convert the image data to float and scale it\n",
    "    image_data = dicom_pixels.astype(np.float32)\n",
    "    image_data -= np.min(image_data)\n",
    "    image_data /= np.max(image_data)\n",
    "\n",
    "    # Create an affine matrix for the NIfTI image\n",
    "    # This is a basic affine matrix, you might need to adjust it based on your DICOM metadata\n",
    "    affine = np.eye(4)\n",
    "\n",
    "    # Create the NIfTI image\n",
    "    nifti_img = nib.Nifti1Image(image_data, affine)\n",
    "\n",
    "    return nifti_img\n",
    "\n",
    "data = {\n",
    "    'img_name': [],\n",
    "    'Z_order_no': [],\n",
    "    'inspection_date': [],\n",
    "    'scan_name': [],\n",
    "    'human_patient_id': [],\n",
    "    'mouse_id': [],\n",
    "\n",
    "    'original_img_name': [],\n",
    "    'inspection_name': [],\n",
    "\n",
    "    'specimen_name': [],\n",
    "}\n",
    "img_id = 0\n",
    "lvl1_keys = list(data_dict.keys())\n",
    "print(\n",
    "    lvl1_keys\n",
    ")\n",
    "for key1 in lvl1_keys[1:2]:\n",
    "    lvl2_data = data_dict[key1]\n",
    "    lvl2_keys = list(lvl2_data.keys())\n",
    "    for key2 in lvl2_keys:\n",
    "        lvl3_data = data_dict[key1][key2]\n",
    "        lvl3_keys = list(lvl3_data.keys())\n",
    "        for scan_name in lvl3_keys:\n",
    "            scan_image_paths = data_dict[key1][key2][scan_name]\n",
    "\n",
    "            if len(scan_image_paths) > 2:\n",
    "                continue\n",
    "            print(scan_image_paths)\n",
    "            for path in scan_image_paths:\n",
    "                new_img_name = f'{img_id}.nii'\n",
    "                ds = dicom.dcmread(path)\n",
    "                try:\n",
    "                    nifti = convert_dicom_to_nifti(np.array([ds.pixel_array]))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue\n",
    "                nifti.to_filename(f'images_2d/{new_img_name}')\n",
    "                #shutil.copy2(path, f'images_2d/{new_img_name}')\n",
    "                img_name = Path(path).stem\n",
    "                data['img_name'].append(new_img_name)\n",
    "                data['original_img_name'].append(img_name)\n",
    "                data['Z_order_no'].append(int(img_name.split('-')[1]))\n",
    "                data['scan_name'].append(scan_name)\n",
    "                img_original_patient_id = '-'.join(key1.split('-')[0:3])\n",
    "                img_mouse_id = key1.split('-')[-1]\n",
    "\n",
    "                data['human_patient_id'].append(img_original_patient_id)\n",
    "                data['mouse_id'].append(img_mouse_id)\n",
    "\n",
    "                date_str = '-'.join(key2.split('-')[0:3])\n",
    "                data['inspection_date'].append(datetime.strptime(date_str, \"%m-%d-%Y\"))\n",
    "                data['inspection_name'].append(key2)\n",
    "                data['specimen_name'].append(key1)\n",
    "                img_id += 1\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('image_data_2d.csv',sep=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(6):\n",
    "    X.append(np.load(f'./2d_dataset_example/data/Xy_{i}.npy')[0])\n",
    "    y.append(np.load(f'./2d_dataset_example/data/Xy_{i}.npy')[1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 320)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet2D, self).__init__()\n",
    "        n_filters = 128\n",
    "\n",
    "        # Convolutional layers with kernel size 3 and no padding (valid)\n",
    "        # Encoder\n",
    "        self.enc_conv1_1 = nn.Conv2d(1, n_filters, kernel_size=3, padding='valid')\n",
    "        self.enc_conv1_2 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "        self.enc_conv1_3 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "\n",
    "        # Max pooling\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Middle encoder layers\n",
    "        self.encode_conv1 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "        self.encode_conv2 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "        self.encode_conv3 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "        self.encode_conv4 = nn.Conv2d(n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout1 = nn.Dropout()\n",
    "\n",
    "        # Upscaling\n",
    "        self.upscale1 = nn.ConvTranspose2d(n_filters, n_filters, kernel_size=2, stride=2)\n",
    "\n",
    "        # Concatenation and Expansion\n",
    "        self.expand_conv1_1 = nn.Conv2d(2 * n_filters, 2 * n_filters, kernel_size=3, padding='valid')\n",
    "        self.expand_conv1_2 = nn.Conv2d(2 * n_filters, 2 * n_filters, kernel_size=3, padding='valid')\n",
    "        self.expand_conv1_3 = nn.Conv2d(2 * n_filters, n_filters, kernel_size=3, padding='valid')\n",
    "\n",
    "        # Final convolutional layer\n",
    "        self.final_conv = nn.Conv2d(n_filters, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = nn.ReLU()(self.enc_conv1_1(x))\n",
    "        x1 = nn.ReLU()(self.enc_conv1_2(x1))\n",
    "        x1 = nn.ReLU()(self.enc_conv1_3(x1))\n",
    "\n",
    "        x2 = self.pool1(x1)\n",
    "\n",
    "        # Middle encoder\n",
    "        x2 = nn.ReLU()(self.encode_conv1(x2))\n",
    "        x2 = nn.ReLU()(self.encode_conv2(x2))\n",
    "        x2 = nn.ReLU()(self.encode_conv3(x2))\n",
    "        x2 = nn.ReLU()(self.encode_conv4(x2))\n",
    "\n",
    "        # Dropout\n",
    "        x2 = self.dropout1(x2)\n",
    "\n",
    "        # Upscale\n",
    "        x3 = self.upscale1(x2)\n",
    "\n",
    "        # Concatenation\n",
    "        delta = [x1_size - x3_size for x1_size, x3_size in zip(x1.size()[2:], x3.size()[2:])]\n",
    "        crop_x1 = x1[:, :, delta[0]//2:x1.size(2)-delta[0]//2, delta[1]//2:x1.size(3)-delta[1]//2]\n",
    "        x3 = torch.cat((x3, crop_x1), dim=1)\n",
    "\n",
    "        # Expansion\n",
    "        x3 = nn.ReLU()(self.expand_conv1_1(x3))\n",
    "        x3 = nn.ReLU()(self.expand_conv1_2(x3))\n",
    "        x3 = nn.ReLU()(self.expand_conv1_3(x3))\n",
    "\n",
    "        # Output\n",
    "        x_out = torch.sigmoid(self.final_conv(x3))\n",
    "        \n",
    "        return x_out\n",
    "\n",
    "    def fit(self, train_loader, num_epochs, device, patch_size, verbose=True):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            for i, (images, masks) in enumerate(train_loader):\n",
    "                images, masks = images.float().to(device), masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(images)\n",
    "                \n",
    "                center_crop = transforms.CenterCrop((outputs.shape[-1], outputs.shape[-1]))\n",
    "                resized_masks = center_crop(masks)\n",
    "\n",
    "                loss = -1 * dice_coefficient(outputs, resized_masks).mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if verbose and i % 1 == 0:\n",
    "                    print(f'Epoch : {epoch} [{i * len(images)}/{len(train_loader.dataset)} ({100. * i / len(train_loader):.0f}%)]\\tLoss: {loss:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIScansPatchDataset(Dataset):\n",
    "    def __init__(self, images, masks, patch_size, transform=None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.patch_size = patch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "\n",
    "        centroid = center_of_mass(mask)\n",
    "        image_patch, mask_patch = self.extract_patch(image, mask, centroid)\n",
    "\n",
    "        if self.transform:\n",
    "            image_patch = self.transform(image_patch)\n",
    "            mask_patch = self.transform(mask_patch)\n",
    "\n",
    "        return image_patch[np.newaxis, ...], mask_patch[np.newaxis, ...]\n",
    "\n",
    "    def extract_patch(self, image, mask, centroid):\n",
    "        y, x = int(centroid[0]), int(centroid[1])\n",
    "        half_patch = self.patch_size // 2\n",
    "\n",
    "        # IF YOU GET THE INDEX OUT OF RANGE ERROR, THEN TRY A SMALLER PATCH SIZE!\n",
    "        # patch must be a square, so in case of setting boundaries, additional padding will be required, which might reduce the quality of model\n",
    "        image_patch = image[y-half_patch:y+half_patch, x-half_patch:x+half_patch]\n",
    "        mask_patch = mask[y-half_patch:y+half_patch, x-half_patch:x+half_patch]\n",
    "\n",
    "        return image_patch, mask_patch\n",
    "    \n",
    "def dice_coefficient(pred, target, smooth=1e-12):\n",
    "    intersection = (pred * target).sum(axis=(1, 2))\n",
    "    return (2. * intersection + smooth) / (pred.sum(axis=(1, 2)) + target.sum(axis=(1, 2)) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu.\n",
      "Epoch : 0 [0/6 (0%)]\tLoss: -0.106727\n",
      "Epoch : 0 [2/6 (33%)]\tLoss: -0.149967\n",
      "Epoch : 0 [4/6 (67%)]\tLoss: -0.000002\n",
      "Epoch : 1 [0/6 (0%)]\tLoss: -0.000735\n",
      "Epoch : 1 [2/6 (33%)]\tLoss: -0.341903\n",
      "Epoch : 1 [4/6 (67%)]\tLoss: -0.401780\n",
      "Epoch : 2 [0/6 (0%)]\tLoss: -0.553395\n",
      "Epoch : 2 [2/6 (33%)]\tLoss: -0.704925\n",
      "Epoch : 2 [4/6 (67%)]\tLoss: -0.745000\n",
      "Epoch : 3 [0/6 (0%)]\tLoss: -0.715000\n",
      "Epoch : 3 [2/6 (33%)]\tLoss: -0.770000\n",
      "Epoch : 3 [4/6 (67%)]\tLoss: -0.765000\n",
      "Epoch : 4 [0/6 (0%)]\tLoss: -0.770000\n",
      "Epoch : 4 [2/6 (33%)]\tLoss: -0.765000\n",
      "Epoch : 4 [4/6 (67%)]\tLoss: -0.715000\n",
      "Epoch : 5 [0/6 (0%)]\tLoss: -0.765000\n",
      "Epoch : 5 [2/6 (33%)]\tLoss: -0.715000\n",
      "Epoch : 5 [4/6 (67%)]\tLoss: -0.770000\n",
      "Epoch : 6 [0/6 (0%)]\tLoss: -0.790000\n",
      "Epoch : 6 [2/6 (33%)]\tLoss: -0.745000\n",
      "Epoch : 6 [4/6 (67%)]\tLoss: -0.715000\n",
      "Epoch : 7 [0/6 (0%)]\tLoss: -0.705000\n",
      "Epoch : 7 [2/6 (33%)]\tLoss: -0.765000\n",
      "Epoch : 7 [4/6 (67%)]\tLoss: -0.780000\n",
      "Epoch : 8 [0/6 (0%)]\tLoss: -0.780000\n",
      "Epoch : 8 [2/6 (33%)]\tLoss: -0.680000\n",
      "Epoch : 8 [4/6 (67%)]\tLoss: -0.790000\n",
      "Epoch : 9 [0/6 (0%)]\tLoss: -0.705000\n",
      "Epoch : 9 [2/6 (33%)]\tLoss: -0.715000\n",
      "Epoch : 9 [4/6 (67%)]\tLoss: -0.830000\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {DEVICE}.\")\n",
    "BATCH_SIZE = 2\n",
    "PATCH_SIZE = 128\n",
    "TRAIN_EPOCHS = 10\n",
    "\n",
    "\n",
    "dataset = MRIScansPatchDataset(X,\n",
    "                               y,\n",
    "                               patch_size=PATCH_SIZE)\n",
    "train_loader = DataLoader(dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "model = UNet2D()\n",
    "model.fit(train_loader,\n",
    "          num_epochs=TRAIN_EPOCHS,\n",
    "          device=DEVICE,\n",
    "          patch_size=PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n",
      "(960, 320)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(100):\n",
    "    X_inst = np.load(f'./2d_dataset/data/Xy_{i}.npy')[0]\n",
    "    y_inst = np.load(f'./2d_dataset/data/Xy_{i}.npy')[1]\n",
    "    print(X_inst.shape)\n",
    "    print(y_inst.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
